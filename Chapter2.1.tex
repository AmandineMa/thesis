\ifdefined\included
\else
\documentclass[a4paper,11pt,twoside]{StyleThese}
\include{formatAndDefs}
\sloppy
\begin{document}
	\setcounter{chapter}{2} %% Numéro du chapitre précédent ;)
	\dominitoc
	\faketableofcontents
	\fi

\chapter{Architectures for Collaborative Robots, Decision and Execution}\label{chap1:sec:archi}
\sectionmark{Architectures for Decision and Execution}

Robots are machine which need to perceive, decide and act. There are multiple ways to endow a robot with such abilities, with different levels of complexity. When a robot has a complex and generic software architecture, based on models which might be inspired from other fields like psychology, philosophy, neurology, it is referred to as cognitive robot or autonomous robots or intelligent robot...We are interested in such architectures but designed to be implemented in collaborative robots. And, we take an interest in a particular function of these architecture: the decision-making, the supervision of the task, of the interaction.

\section{Existing Architectures for Collaborative Robots}\label{chap1:subsec:archi}
``An integrated cognitive architecture can be defined as a single system that is capable of producing all aspects of behaviour, while remaining constant across various domains and knowledge bases''~\cite[p.~104]{chong_2007_integrated}. Kotseruba and Tsotsos reviewed cognitive architectures starting 40 years ago until nowadays. They accounted around three hundred of them and chose to focus their review on 84~\cite{kotseruba_2020_40}. However, the term \emph{cognitive architecture} often refers to an architecture modeling human cognition~\cite{howes_1997_role} and what interest us is to endow robots with cognitive and interactive abilities, not always basing ourselves on human cognition.  

Some cognitive architectures such as ACT-R has been adapted for human-robot interaction (ACT-R/E)~\cite{trafton_2013_act}. The architecture aims at simulating how humans think, perceive and act in the world, strongly based on theory of mind. It is interesting but to understand humans is not enough to make the robot a good collaborators for them, as it lacks abilities concerning the human-aware task and action execution. 

A very complete architecture, CRAM, dealing with problems such as manipulation, perception, plans or beliefs management has been developed by Beetz \etal~\cite{beetz_2010_cram}. However, this architecture is more designed for a robot acting alone than a robot acting in collaboration with a human.

The work of Scheutz and colleagues is compelling, as they proposed a generic architecture, DIARC, for cognitive robots collaborating with humans~\cite{scheutz_2006_utility,scheutz_2019_overview}. In this context, it handles perception, dialogue and different kind of actions. But, the architecture lacks real modeling and awareness of the human at each level.

Another architecture worth to be mentioned is the DAC-h3 architecture by Moulin-Frier, Fischer \etal, inspired from biology~\cite{moulin_2017_dac}. It is designed for a robot maintaining social interactions with humans, able to tell narratives and to acquire knowledge thanks to its interactions with humans. As it is mainly dedicated to knowledge acquisition and expression, it lacks planning and execution abilities.

Finally, there is the architecture developed and implemented by Lemaignan and colleagues for collaborative robots. All deliberative components of the architecture are human-aware~\cite{lemaignan_2017_artificial}, \ie all of components except the sensorimotor layer. This architecture is based on the philosophical BDI model developed by Bratman~\cite{bratman_1987_intention,bratman_1988_plans}. It has 3 main concepts defined as the following in computer science:
\begin{bulletList}
	\item \emph{Beliefs}: They are a representation of the agent’s knowledge about the world. ``[They] can be viewed as the informative component of system state''~\cite[p.~313]{rao_1995_bdi}. It is not the word ``knowledge'' that has been chosen to define this concept because what the agent perceives of the environment is in fact the likely state of the environment. There is no certainty, its sensors are not accurate or could malfunction. This way of distinguish knowledge and beliefs is one that can be found in the literature of distributed computing~\cite{lamarre_1994_knowledge}.
	\item \emph{Desires}\footnote{In one of the first implementation, PRS, ``Goals'' notion was used instead of ``Desires''~\cite{georgeff_1989_decision}, then they use it in a interchangeable way in~\cite{georgeff_1991_modeling} and finally choose ``Desires''~\cite{rao_1995_bdi} with the definition given in the AI literature, \eg desires can be many at any instant and may be mutually incompatible. Therefore, a goal will be a chosen desire~\cite{cohen_1990_intention} and concurrent goals are consistent.}: They are a representation of the motivational state of the system. They provide ``information about the objectives to be accomplished or, more generally, what priorities or payoffs are associated with the various current objectives''~\cite{rao_1995_bdi}. 
	\item \emph{Intentions}: They are a representation of the currently chosen course of action (plan). It is the deliberative component of the system. The selected course(s) of action are determined with a deliberative function, according to the beliefs and desires~\cite{rao_1995_bdi}.
\end{bulletList}

\section{Lack and needs... TO BE DONE}

\section{The new LAAS Architecture... voir si votre archi a un nom}

\subsection{Specificities...}

\subsection{Overall architecture explanation}

In this section, we will shortly present an overview of the robotic architecture that has been developed inside the RIS team of LAAS-CNRS. The purpose of this overview is inform the reader about the inputs available for \acrshort{jahrvis}. Two instantiations of this architecture for two different tasks will be described in Chapter~\ref{chapter:chap3} and Chapter~\ref{chapter:chap4}. This architecture model, shown in Figure~\ref{chap2:fig:archi}, has been inspired by the architecture developed by Lemaignan and colleagues~\cite{lemaignan_2017_artificial}, mentioned in Section~\ref{chap1:subsec:archi}. All communication between the components goes through ROS~\cite{quigley_2009_ros}.

\begin{figure}[!ht]
	\includegraphics[width=\linewidth]{figures/chapter2/archi_overview.pdf}
	\caption{Overview of the RIS architecture}
	\label{chap2:fig:archi}
\end{figure}

\subsection{Architecture components}\label{chap2:sec:rob_archi}

\subsubsection{Situation Assessment}
The Situation Assessment has two roles:
\begin{enumerate}
	\item  to gather different perceptual information and build a geometric representation of the world (\ie elements have associated 3D coordinates), composed of objects and agents; from this world representation, the module runs reasoning processes to interpret it in terms of symbolic statements between the objects themselves and between the involved agents and the objects. Such component can be implemented with frameworks like Toaster~\cite{milliez_2014_framework} or Underworld~\cite{lemaignan_2018_underworlds}.
	\item estimate the human's perspective and build an estimation of their world representation; it is the first step allowing to implement the theory of mind principles (see Section~\ref{chap1:subsec:tom}).
\end{enumerate}

Thus, the Situation Assessment outputs data, which we call \textit{symbolic facts}, such as \fact{isOnTopOf}{cube\_1}{cube\_3} or \fact{isReachableBy}{cube\_2}{human\_0}. The first element of this triplet is called the property, the second one is the subject and the last one is the object.

\subsubsection{Knowledge Base}

During an interaction, each agent has their own knowledge base, as they can have belief divergences. A Knowledge Base is divided into two parts :
\begin{enumerate}
	\item The \textit{semantic} part is in charge of representing the environment elements meaning, the objects' and agents' types, their applicable properties, the descriptions and parameters of the actions, a part of the language model with verbs or pronouns, and their names in natural language. 
	
	Besides, it is also in charge of representing the current symbolic world-state (the computed facts) and thus the instantiation of the concepts in terms of physical (\eg this particular block) or abstract (\eg this particular action instance) entities.
	\item  The \textit{episodic} part is a timeline, keeping track of the symbolic facts computed over time, either by the Situation Assessment, the Semantic Knowledge Base or the Supervisor.
\end{enumerate}

The Supervisor can subscribe to a given type of fact, allowing to receive every fact update of this type. For example, the Supervisor can ask to receive every update (addition or deletion) of any fact belonging to the type \fact{isOnTopOf}{Cube}{Table}. In this case, it will receive the addition of \fact{isOnTopOf}{cube\_2}{table\_1} but not of \fact{isOnTopOf}{spoon}{table\_1}. It can also query an information when needed (\eg the Supervisor can ask the human understandable name of pick\_action which is ``pick'').

\subsubsection{Human-Aware Motion Planners and Execution}
The motion planners allow the robot to execute human-aware motion actions. According to the task needs, several planners might be involved for a same task. Indeed, in a task requiring object manipulation, the robot will need a motion planner able to plan for pick, place and drop actions, such as MoveIt\footnote{\url{https://moveit.ros.org/}} or GTP which is human-aware~\cite{waldhart_2016_novel}, and a home-made software handling the execution these trajectories\footnote{\url{https://github.com/YannickRiou/pr2_mtc}}. Moreover, in collaborative tasks, an agent might be led to hand over an object to their partner, in this case could be used a dedicated planner~\cite{mainprice_2012_sharing}. Finally, the robot might need to move in the environment, but when moving in a environment with humans, it should navigate being aware of them for safety and legibility. Thus, the robotic architecture should integrate co-navigation planner and executor such as HATEB-2~\cite{singamaneni_2020_hateb}. 

These planners produce trajectories and moves on request of the Supervisor. During execution, they sends feedbacks about the state execution, in this way the Supervisor can receive data about something going wrong or the estimated remaining time of execution. 

\subsubsection{Human-Aware Task Planner}
We can distinguish two situations in which a collaborative robot needs a human-aware task planner: 
\begin{inlineEnumerate}
	\item when it performs a task on its own but a human is nearby, and
	\item when it performs a task with a human.
\end{inlineEnumerate} 
In the first situation, it might consider asking the human's help whereas in the second one it needs to plan for both agents' actions. 

The human-aware task planner generates a shared symbolic plan in which each agent, human and robot, has actions of the task assigned to them, depending on some criteria. However, the human is neither an agent that the planner can directly control or an agent that will know the complete plan. Thus, it allows the robot to plan by emulating the human decision, action, and reaction processes. 

\subsubsection{Supervision}
The Supervision is the puppet master of the system, embedding the robot high-level decisions, controlling its behavior and trying to react to contingencies, always considering the human it is interacting with. It is not standalone, relying on the components described above to be able to take decisions, be aware of the environment and make the robot moves.
\newline

After giving an overview of the components on which the supervision relies, we present the context in which we place ourselves for human-robot collaboration.



\ifdefined\included
\else
\bibliographystyle{acm}
\bibliography{These}
\end{document}
\fi