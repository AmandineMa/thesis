\ifdefined\included
\else
\documentclass[a4paper,11pt,twoside]{StyleThese}
\include{formatAndDefs}
\sloppy
\begin{document}
\fi


\chapter*{Conclusion}
\addstarredchapter{Conclusion} %Sinon cela n'apparait pas dans la table des mati√®res
\markboth{Conclusion}{}


In this thesis, we proposed several contributions focusing on investigating the main concepts of joint action and implementing a number of decisional processes in order to make the robot a good task partner for the human. There are four main elements: an extensive review of joint action, a supervision system dedicated to human-robot collaboration, a model and tools to allow the robot to evaluate in real-time the \acrlong{qoi} its point of view. And, the last contribution is the participation to the deployment, in a realistic setting, and evaluation of collaborative tasks ran on a robot fully autonomously, in particular in a Finnish mall. 

We started our journey with an exploration of social science literature around social interaction, collaboration and joint action. We first analyzed how a social interaction is defined and its structure. It is two people or more, being aware of each other and knowing that their acts and behaviors can influence the other. Usually, in a social interaction is an opening, ``something'' in the middle and then a closing. This frame given by sociology helped us to defined what we called ``interaction sessions'' in the context of \acrshort{hri}. Then, we explored what is beyond the term \acrfull{tom} which is the ability to represent others' unobservable mental states (\ie their intentions, beliefs, knowledge, goals)... Next, we dwelt on joint action and the processes on which it relies. Joint action is the frame in which we place our human-robot collaborative tasks. Finally, we studied communication, which can be verbal and non-verbal.

Then, we showed that a thoroughly conceived architecture, especially dedicated to collaboration, is important and presented our dedicated LAAS architecture: \acrfull{dacobot}. We introduced the components of the architecture: the Situation Assessment, the \acrlong{kb}s, the Human-aware Motion Planners and Executors, the Human-aware Task Planners and the Supervision system. All these components were devised with the idea that they will be integrated into an architecture that will be human-centered. As the goal is to handle quite complex tasks, the architecture is quite complex itself. This is why the Supervision has a very important coordinating role regarding the other components and the management of the interaction with the human. 

We defined a number of criteria that a supervision for human-robot collaboration should meet: to be generic, to take into account the human partner, to leave decisions to them, to monitor human actions, to handle contingencies, to manage relevant communications, to consider the interaction outside collaborative tasks, and to adapt to the human experience, abilities or preferences. \acrfull{jahrvis}, ours, managed to meet on number of these criteria, mainly the genericity, the explicit consideration of the human partner goals, actions, beliefs, decisions and preferences. It provides as much latitude as possible to the human and, finally, monitor their actions. The management of relevant communications and the interaction outside collaborative tasks have been a bit tackled but are still opened problems for \acrshort{jahrvis}, as well as the contingency handling and the adaptation to the human experience and abilities. \acrshort{jahrvis} relies on joint action and collaboration principles to perform a task with a human. Indeed, it considers \acrlong{tom}, joint attention, shared representations, monitoring, common ground and joint commitment.

Finally, the robotic architecture and \acrshort{jahrvis} were demonstrated with three tasks: the StackBuildingTask, the Direction-giving task and the Director Task. Three is not a lot but still allows to see that the system can be used in different contexts. The StackBuildingTask shows the ability of \acrshort{jahrvis} to handle shared plans. The direction-giving task was a real team challenge as deployed in a real-world environment for several months. It was a fertile ground to carry out a user study and to complete a proof of concept for the \acrshort{qoi} Evaluator. And, the Director Task was interesting to investigate perspective-taking and communication issues. We found it so interesting that we thought it was a good idea to submit it to the \acrshort{hri} community as a task to take up challenges and eventually compare results between research teams.



\section*{Limitations and Future Work}
\markright{LIMITATIONS AND FUTURE WORK}

We had a lot of ideas but implemented only a few of them. To build a supervision system to endow a robot with autonomy when performing collaborative tasks with a human is not an easy thing, especially when thinking to genericness and re-usability. The work presented in this thesis provides a basis for an even more elaborate system, handling contingencies, and with a more refined interaction session manager which could integrate a nice goal negotiation component. Moreover, once the robot performs quite well with one task and one human, why not add other humans and/or other tasks in parallel?

Even though our autonomous system works quite well, it is fragile in the sense that, if it was in a task with a human acting exactly the same way as they would interact with another human, it would be helpless. Indeed, there are among other things, computing latencies in each component. Thus, the robotic architecture does not function at very high frequency, cumulating the latencies. 

It would be interesting that the robotic and \acrshort{hri} communities make an effort to have even more open-source software so we could integrate components in a more easily way. To be able to choose the most effective technology for each feature (speech recognition, action recognition, planning, navigation,...) would allow to perform much better architectures.

%future work : to be interruptible to do another task with someone else when already performing a task, when it is possible and socially acceptable
% gestion de buts
% action monitoring : pouvoir reconnaitre plus de types d'action (idle, answering the phone etc and so distinguish the ones the human is doing for the task or other actions outside the task)
%on communication, to take inspiration from Decision-Making for Bidirectional Communication in Sequential Human-Robot Collaborative Tasks
% user study
% robot action execution : distinguish planning and execution for what the human can see

\ifdefined\included
\else
\bibliographystyle{acm}
\bibliography{These}
\end{document}
\fi