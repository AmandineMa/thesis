\ifdefined\included
\else
\documentclass[a4paper,11pt,twoside]{StyleThese}
\include{formatAndDefs}
\sloppy
\begin{document}
\setcounter{chapter}{0} %% Numéro du chapitre précédent ;)
\dominitoc
\faketableofcontents
\fi

\chapter{Human, Robot and Interaction Models: the Funding Principles of a Decision-Making System for Human-Robot Collaboration}
\label{chapter:chap1}
\chaptermark{Human, Robot and Interaction Models}
\minitoc

This first chapter aims at setting the context for this thesis. First, we present some related works on human-human and human-robot social interactions. These works nourished the thoughts which led to this manuscript. Then, we develop key elements for collaboration such as joint action, commitment and shared plans. Finally, we explore \acrfull{bdi} and cognitive robotic architectures  which have inspired us to design our own architecture in which, \acrshort{jahrvis} —  the main contribution of this thesis — endows a robot with the abilities not only to control, but also to evaluate its joint action with a human. 


\section{Social interactions}\label{chap1:sec:soc_int}\todo{check refs to CA}

\subsection{How to define a social interaction?}
First, let’s take a look at the dictionary and see how the word ``interaction'' is defined. According to the Oxford dictionary, an interaction is a ``reciprocal action or influence'' and more precisely a ``communication or direct involvement with someone or something''. As for the Cambridge dictionary, it defines it as an occasion when two or more people or things communicate with or react to each other''. Those definitions can give an hint about what it an interaction between humans but they are not specific enough. Now, going through social psychology literature, one of the first attempt to define ``social interaction'' was by Goffman~\cite{goffman_1967_interaction}. He distinguished three basic interaction units: the social occasion, the gathering and the social situation. The social occasion is an event that is temporally and spatially situated in such a way that it forms a unit that can be looked forward and back upon, by participants that are informed by the event (dinner, meeting, sport game...). The gathering refers to any set of two or more individuals who are at the moment in one another’s immediate presence. It can be noted that a social occasion may include several gatherings but that gathering do not need social occasions to occur (they can happen in office spaces, street corners, restaurants…). The social situation refers to the full spatial environment that embraces interacting people. It is created as soon as people engage in interaction, when mutual monitoring occurs and ends when the next to the last person leaves. Furthermore, Goffman distinguished between focused and unfocused interaction (gathering). A focused gathering has its members that can come together to sustain a joint focus of visual and cognitive attention and are open to each other for talk. He calls it encounters or engagements. On the other hand, an unfocused gathering has its members present to one another but not engaged together (\eg persons waiting for a bus). In this same book, Goffman proposed a definition of social encounter: ``an occasion of face-to-face interaction, beginning when individuals recognize that they have moved into one another’s immediate presence and ending by an appreciated withdrawal from mutual participation''.

A couple of years later, Argyle wrote a book entitled Social Interaction~\cite{argyle_1973_social}, where he laid the foundations to understand social interactions. He came to the view that social interaction could be interpreted as a set of social skills, and that it may therefore be possible to train these skills the same way as manual skills are trained. For example, during an encounter between two persons, each must be able to perceive the social cues (verbal or non-verbal signals) of the other which are then filtered through the perspective each has acquired through socialization and experience.  The interpretation of context and social cues is then applied to arrive at a definition of the situation, which in turn guides both behavior and action.

Then, Rummel proposed a definition of a few words: ``Social interactions are the acts, actions, or practices of two or more people mutually oriented towards each other's selves. It is behavior that tries to influence or take into account another's subjective experiences or intentions''~\cite{rummel_1976_understanding}.

The elements brought here, trying to define what is an interaction and more precisely a social interaction, are chosen among a large amount of work. It is possible to find different definitions.

\subsection{Structure of a social interaction}\label{chap1:subsec:social_int}
Most of the research about interaction and social interaction belongs to the field of social psychology. As for the structure of a social interaction, it is more from the field of Conversation Analysis (CA) which mixes sociology, anthropology, linguistics, speech-communication and psychology.

Robinson makes a review of the work that has been done about \textit{overall structural organization}~\cite{robinson_overall_2012}. Most of the time in the literature, overall structural organization is discussed in terms of ``the overall structural organization of entire, single occasions of interaction''. Then, the \textit{overall structural organization} term is generally used to talk about one particular (albeit large) unit of interaction. However, many different types of interactional units can have an overall structural organization. For example, Schegloff encouraged to recognize ``‘overall structural organization’ not as something for the unit ‘a single conversation’ (or encounter, or session, etc.) alone, but for units like turns, actions and courses of action (like answering or telling), sequences, and who knows what else as well''~\cite{schegloff_2011_word}. He also mentioned that every unit of organization should probably have a local organization and a global organization. Here, the term \textit{overall structural organization} refers to ``the overall structural organization of entire, single occasions of interaction''. 

Robinson tells us that this concept has received relatively little analytic attention and thus is still not well understood~\cite{robinson_overall_2012}. Indeed, research has been more focused on analyzing the organization of individual sequences of action such as turn-takings or conversation openings. Several terms have been used to talk about a \textit{supra-sequential coherence}: big package, set of pre-organized sequences, (social) activity, project of activity or plan of action. Sacks gave the following definition for the overall structural organization of single occasions of interaction: it ``deals, roughly, with beginnings and endings, and how beginnings work to get from beginnings to something else, and how, from something else, endings are gotten to. And also the relationship - if there is one - between beginnings and endings''~\cite[p.~157]{sacks_lectures_1995}. Robinson summarized research about the subject by saying that single occasions of interaction (in a generic or context-free sense) are normatively organized as: (1) beginning with an opening (2) ending with a closing and (3) having ``something'' in between opening and closing'' which can be referred to as topics~\cite{robinson_overall_2012}.

\subsubsection{Opening}
Openings are used to begin an encounter. One of the main reference on the subject is the work of Schegloff~\cite{schegloff_1986_routine}. Openings and related issues vary depending on the nature of interactions. For example, opening of a phone call to a family member or a friend will be organized as follow: (1) summons-answer (the one calling talks first) (2) identification/recognition of each other (3) greetings and (4) how-are-you. Whereas, in primary-care medical visits, opening is sequenced as: (1) greeting (2) securing patients’ identities (2) retrieving and reviewing patients’ records and (4) embodying readiness (sitting down and facing one another). More examples from the literature can be found in (Robinson, 2012). 

Another work, by Kendon~\cite{kendon_1990_conducting}, focuses on the greeting part, but more precisely the greeting behavior with the associated non-verbal cues. The greeting behavior is divided in three main phases: the distance salutation, the approach and the close salutation. 
The distance salutation only occurs if the greeters as far enough such as they need to get closer if they wish to continue the interaction. This phase starts after one or both participants sight one another and at least one of them identifies a wish to engage in a greeting. In case one of the participant has not seen the other one, he signals his presence by vocalizing the other one’s name or by clearing his throat. Then, they orient their bodies towards each other and exchange glances in a subtle acknowledgement that the greeting is desired by both. During this phase, people can also wave or give a sign with their head (\eg nod).
The approach is divided into two sub-phases: the distant approach and the final approach. During the distant approach, people tend to look away whereas when the final approach starts (the greeters are 3 meters or less from one another), they look back at each other and, they smile.
Finally, there is the close salutation, the most normalized phase of the greeting. It happens when people are 1,5 meters or less from each others. Then, they can have a non-contact close salutation during which people exchange verbal greetings, or they can hand-shake or embrace (or do something else according to their culture). The greeting is over.

\subsubsection{Topics}
Episodes of interaction vary a lot in their contextualized nature, which leads to a large variety of topics and sequences of topics. Interactions that happen in ordinary or institutional contexts can be pre-organized around one or more topics. Robinson gave examples such as an emergency call or an expected call back by a friend to discuss an expected single item of business~\cite{robinson_overall_2012}.

\subsubsection{Closing}
Schegloff is one of the reference on closing as well~\cite{schegloff_1973_opening}. A closing can be divided into two phases: the topic termination and the leave-taking.
The topic termination has a pre-closing statement which signals to the partner the wish to close the conversation. Then, the leave-taking follows the pre-closing statement and its response and, includes the goodbye exchange. Finally, the partners break co-presence, \ie physically walk apart.\footnote{It is not explicitly mentioned in~\cite{schegloff_1973_opening}  but they precise in a footnote that it would not make sense if the parties remain in co-presence after having being through the closing sequence.} In the context of a phone call, Clark and French defined this co-presence breaking as the \textit{contact termination} when people hang up~\cite{clark_1981_telephone}.

With regards to non-verbal cues, Knapp \etal{} listed and analyzed them~\cite{knapp_1973_rhetoric}. The more frequent are eye contact breaking, head nodding, leaning toward the partner and positioning in the direction of the way of leaving.

\section{Human-Robot Social Interactions}

Now that we have seen how social interactions look like when happening between humans, we are going to see the different ways the human-robot interaction field divided and categorized interactions. It is possible to define an interaction according to its length as we will show in Section~\ref{chap1:subsec:inter_lengths}. Then, inside the interaction, what are the different temporal phases? We will see it in Section~\ref{chap1:subsec:inter_div}. Next, in Section~\ref{chap1:subsec:inter_hier}, we will take an interest in a different way to segment interactions: with hierarchical levels. Finally, some authors proposed some interaction patterns, we will present a few in Section~\ref{chap1:subsec:inter_patt}.

\subsection{Interaction lengths}\label{chap1:subsec:inter_lengths}
\paragraph{Short-term Interactions}
Zheng \etal{} defined a \textit{short-term interaction}~\cite{zheng_2013_designing} based on the Unified Theories of Cognition of Newell~\cite{newell_1994_unified}. A short-term interaction corresponds to the ``cognitive band'' of cognition, during which they focus on individual utterances and speech acts for interactions that last for tens of seconds. They left aside longer-term interactions that can be in the ``rational band'' (minutes to hours) or the ``social band'' (days to months).
Gaschler \etal{} deployed a bartender robot and defined a short-term interaction as being a customer ordering a drink – from the attention request towards the bartender to the closing of interaction by payment and exchange of polite phrases~\cite{gaschler_2012_modelling}.
Iocchi \etal{} used the \textit{short-term} to refer to short interactions and that are focused on only one particular communicative objective, avoiding long and complex interactions~\cite{iocchi_2015_personalized}.
Sanelli \etal{} gave three characteristics to a short-term human-robot interaction: (1) users are not familiar with the robot (2) each interaction happens with a different user (3) interaction is short in time. Then, the robot has not memory of past interactions~\cite{sanelli_2017_short}.

\paragraph{Long-term Interactions}
A survey~\cite{leite_2013_social} has been done by Leite \etal{} about long-term human-robot interactions, where long-term means, most of the time, several interactions between the same human and robot. They defined four contexts for which social robot\footnote{actually, some of the robots featured in the survey are not social robots such as a Roomba or the Personal Exploration Rover (PER)} for long-term interaction have been designed: health care and therapy, education, work environment and public spaces, and people's homes. 

For example, Kanda \etal{} performed a field trial at an elementary school in Japan for two months~\cite{kanda_2007_two}. The children were able to interact with the robot for 32 days in total, during 30 minutes after lunch. The robot could switch between one hundred pre-defined behaviors (\eg hugging, shaking hand or singing) but not all of them were available during the first interactions with a human. Indeed, they had integrated a pseudo-development mechanism, \ie the more a child interacts with the robot, the more different behaviours the robot displays to that child. Also, the robot confided personal-themed matters to children who have often interacted with it (\eg ``I don't like the cold''). These abilities allowed the robot to maintain the children's interest even after the first week whereas in a first experiment where the robot's behavior was the same all along the two months, most children stopped to interact with the robot from the second week. 

In their discussion, Kanda \etal{} raised an interesting question: `` How Long Should \textquoteleft Long-Term\textquoteright{} Be? They found out that some authors consider that two months is a long-term interaction. They also pointed that some Human-Computer Interaction studies on long-term interaction last five weeks. In their survey, Leite \etal{} gave their point of view, which seems well-thought. They argued that it is more important to look at the number of interaction sessions and the length of these sessions (a five minutes-interaction is different from a one hour-interaction). For them, an interaction can be considered as long-term when the user becomes familiarized with the robot to a point that their perception of such robot is not biased by the novelty effect anymore. This definition raises another question: when does user’s familiarization with the robot become stable? But we will not discuss it here.

\subsection{Interactions divided in phases}\label{chap1:subsec:inter_div}
Among works on short-term or long-term interactions, some authors divided interactions in phases which have sometimes similarities with the phases of social interactions described in Section~\ref{chap1:sec:soc_int}.

Gockley \etal{} divided an interaction in three phases: greeting, core of the interaction and departure~\cite{gockley_2005_designing}. In the greeting phase, Valerie, the robot receptionist, greets people who might be interested in engaging in conversation. Thus, people are classified into ``attentional'' states:
\begin{bulletList}
	\item present (people a bit far and moving): Valerie doesn’t pay attention to them
	\item attending (people closer): Valerie greets them
	\item engages (people next to the desk but on the side): Valerie acknowledges their presence but does not expect input from them
	\item interacting (people in front of the keyboard): Valerie prompts them for input if they are not typing.
\end{bulletList}
In the core of interaction, either Valerie can tell her (fictive) story or chat. Her story is subjective and evolve over time. It is about her social life, her lounge singing career, her therapy business, and her job as a receptionist. Furthermore, Valerie has a chatbot system which is very simple. Finally, inputs from visitors are from a keyboard, for easier control and reliability. Finally, at departure, when a person leaves the ``interacting'' region, Valerie signals the end of the interaction by saying ``goodbye''. 

Kidd and Breazeal presented robot which is a weigh loss coach~\cite{kidd_2008_robots}. They introduced here the notion of states of relationship. They are three: initial (for the first few days of interaction), normal, repair. According to the state of relationship, the robot answers/questions/speech will not be the same. Kasap and Magnenat-Thalmann designed their system so, to each user, corresponds an interaction session~\cite{kasap_2012_building}. Each session is composed of four dialogue phases: welcome, warm up, teach and farewell. The system has a memory of users and past interactions. In the memory, is recorded the context (initial state and goal), contents (events) and the outcome (goal succeeded or not). A bit similar to the relationship state defined by Kidd and Breazeal~\cite{kidd_2008_robots}, they defined a notion that they call relationship level. It is computed based of the emotional interactions from the episodic memory associated to a user. It influences the mood level of the robot and then the facial expression and the speech.

In the work around the bartender robot~\cite{gaschler_2012_modelling}, they divided the interaction in three phases (or states) but from two different viewpoints, the of the customer and the one of the bartender. From the customer viewpoints, the phases are: (1) attention request towards bartender (2) ordering of one or more beverages, and (3) closing of interaction by payment and exchange of polite phrases. Then, in reaction of each phases, there are the ones from the bartender viewpoint: (1) acknowledging the attention request, (2) serving the ordered drink, and (3) asking for payment.
They left open the possibility to have sub-phases inside phases.

We can also find, in Lee \etal{}' work~\cite{lee_2012_personalization}, the notion of structure of interaction: interactions start with the vendor identifying the customer, greeting and engaging in small talk with the customer, engaging in the snack transaction, and then enacting social leave-taking.

\subsection{Hierarchical interactions}\label{chap1:subsec:inter_hier}
Not only, interactions can be divided in phases but also in levels. For example, Dautenhahn and colleagues~\cite{dautenhahn_2002_embodied, ogden_2001_interactional} defined two levels of approach for interactions, a global one and a local one. The \textit{global level approach} defines a unit of interaction as being relatively large (long sequences of interaction or large units of interaction), such as the script for a greeting as described by Kendon in~\cite{kendon_1990_conducting}. At this level, an interaction may be seen as a unit similar to a schema or script, in the computer/cognitive science senses of these terms. They named this level of interaction a ``Global Interactional Unit (GIU)''. Furthermore, a GIU can be divided in phases, each of which has associated behaviors. Behaviors have meaning and their meaning depends on the phase in which they occur, the context (\eg a ‘wave hello’ vs. a ‘wave goodbye’). Their \textit{local level approach} is a much smaller unit, often as simple as an action and a response to that action. They claimed that this view of interaction has the advantage of greater flexibility and robustness compared to the globally structured view. Flexibility is a result of the possibility of specifying acts that may occur in many global interactional structures. But, as contextual details are ignored, the ability to assign a specific meaning to an action is lost.

In his thesis, Kuo insists about this flexibility and the re-usability~\cite{kuo_2012_designing}. A lower level of design is more appropriate for reuse. For him, a unit of interaction corresponds to an ``interaction cue'' (or social cue) that a robot can perceive and act upon or express in an interaction. These cues can be verbal, non-verbal, or a combination of both (multi-modal interaction). A complete episode of interaction should be constructed through composition of interaction cues with some common patterns repeated over the course of the interaction (\eg awareness of human presence).

\subsection{Patterns of Interaction}\label{chap1:subsec:inter_patt}
Before talking about design patterns or interaction patterns, Goffman argued that human interactions follow a specific ``order'' and characterized a number of patterns in which people interact, such as how greetings unfold and how people leave an interaction~\cite{goffman_1983_interaction}.

Kahn \etal{} introduced design patterns~\cite{kahn_2008_design}, that they will later called interaction patterns in~\cite{kahn_2010_validating}, inspired from computer science. They proposed rules to follow using them and eight patterns. The two main ideas to retain is that a sequence of patterns has to be well ordered and that patterns can be hierarchical. 
The 8 patterns: 
\begin{bulletList}
	\item The initial introduction: largely scripted, conventionally-established verbal and behavioral repertoire to recognize the other, inquire politely about the other, engage in some physical acknowledgment (\eg handshake)
	\item Didactic communication: one-way communication of information 
	\item In motion together: walk together
	\item Personal interests and history: sharing of personal interests and history with others
	\item Recovering from mistakes: creates the potential for both parties to maintain a social affiliation following the mistake
	\item Reciprocal turn-taking in game contextual: taking turns with one another when playing games
	\item Physical intimacy: to engage in holding or touching or embracing
	\item Claiming unfair treatment or wrongful harms: allows to make claim to its moral standing
\end{bulletList}


Following the same idea and going further, Sauppé and Mutlu introduced the interaction blocks~\cite{sauppe_2014_design}. Compared to Kahn’s work, they created a pattern language and a tool/environment to design human-robot interaction. To conceive their patterns, they collected and analyzed data from 5 kinds of interaction scenarios: Conversation, Collaboration, Instruction, Interview and Storytelling.
Then, they identified common interaction structures, which served as ``design interaction patterns'':
\begin{bulletList}
	\item Introductory monologue: A short introduction can be used to introduce other participants to a scenario by giving an overview of the remainder of the interaction or it can be a greeting for example.
	\item Question and Answer: A question is a sentence meant to elicit information from other participants. An answer is the response to a question that aims to satisfy the questioning participant’s curiosity.
	\item Generic Comment and Personal Comment: A comment is a short statement offering the speaker’s opinion. Comments are either generic (\eg, ``Wow'') or personal (\eg, ``I tried that and didn’t like it'').
	\item Monologue and Generic Comment: A monologue is a longer form of speech during which no response is expected.(\eg telling of a story). Although monologues expect no response, listeners may occasionally offer unsolicited commentary.
	\item Instruction and Action: An instruction is a command offered by one participant to direct the actions of another participant. The proper response to this instruction is often an action, although the action might follow the instruction with a delay depending on whether it is an appropriate time to perform that action
	\item Finished Comment: Upon the completion of the goals of the scenario, one or more of the participants will note that the scenario is completed by offering a finished comment.
	\item Wait: One pattern implicit in all scenarios involving two or more participants is the wait pattern.
\end{bulletList}
Finally, they designed a software to easily implement those patterns in a robot.

In his thesis, Kuo criticizes Kahn’s work~\cite{kuo_2012_designing}. He says that these patterns involve sequences of interaction cues and should be decomposed to a lower level for detailed design and reuse. He proposed his own patterns:
\begin{bulletList}
	\item Human presence detection: detect when there is a person who might be interested in
	\item Showing interest for interaction: express the robot’s awareness of a user’s presence around it and its interest and willingness to interact
	\item User’s attention on the robot: Know when a user is paying attention to the robot in an interaction and its information on its screen
	\item User identification by face: Provides the fundamental block for personal service and social interaction by recognizing the human counterpart in an interaction
\end{bulletList}
He checked the validity of his patterns with the analysis of Problem statement, Context of Use, Interaction Modality, Combination with Other Patterns, Technical Performance and Limitations, User Feedback and User’s Perception, Resulting Interactive Behavior.

Finally, Peltason and Wrede also based their work on design patterns from computer science, specifically applied to dialogue here~\cite{peltason_2010_pamini}. To name a few of them: Simple action request, Interaction opening, Interaction closing, Clarification. During interaction, the registered patterns are employed in a flexible way by admitting that patterns can be interrupted by other patterns and possibly resumed later which leads to interleaving patterns. By default, simpler patterns are permitted to be nested within temporally extended patterns.

\section{Around the Joint Action Concept}
Often, multiple concepts are addressed when referring to collaborative tasks: collaboration, cooperation, coordination, joint action, joint activity, shared/joint attention, shared/joint intention, shared plan, shared/common/joint goal, (joint) commitment, engagement, mental states, theory of mind, mutual knowledge... However, many terms and definitions, whether inside a field\footnote{Here, philosophy, psychology or robotics} or between fields do not reach a consensus. This can be quite confusing, especially for roboticists for which it is initially not the range of expertise. Thus, we will first give an overview of the more characteristic definitions of what is Joint Action. Then, we will present a non-exhaustive set of notions related to Joint Action. 

A part of this work on Joint Action, realized in the context of the JointAction4HRI project\footnote{https://jointaction4hri.laas.fr/}, is the result of the collaborative work with Kathleen Belhassein, a PhD student in psychology, and V{\'\i}ctor Fern{\'a}ndez Castro, a post-doctoral researcher in philosophy. It has been the subject of a publication in the book Culturally Sustainable Social Robotics~\cite{belhassein_2020_horizontal}, a publication under submission at Acta Psychologica~\cite{belhassein_2021_adressing} and a publication under submission in a volume of the Book Serie Techno:Phil~\cite{castro_2021_adressing}.

\subsection{How to define Joint Action?}

An important number of social interactions and encounters are encompassed by the notion of joint action. Broadly considered, joint action is any form of social interaction whereby two agents or more coordinate their actions in order to pursue a joint goal. However, the notion of joint action has particularly been subject to debate in philosophy and psychology. For instance, according to Sebanz \etal~\cite[p.~70]{sebanz_2006_joint}, ``joint action can be regarded as
any form of social interaction whereby two or more individuals coordinate their actions in space and time to bring about a change in the environment.''; while other authors~\cite{carpenter_2009_just, cohen_1991_teamwork, fiebich_2013_joint, tomasello_2005_understanding,pacherie_2012_agency} resist the idea that instances of mere coordination – \eg two partners walking side by side – constitute a joint action, considering that it requires some necessary conditions like sharing goals and intentions.

Moreover, while the notion of joint action is used interchangeably with the notion of collaboration or cooperation for some authors such as Becchio \etal~\cite{becchio_2010_toward} and Kobayashi \etal~\cite{kobayashi_2018_language}, other authors establish a hierarchy of interactions depending on the processes involved~\cite{amici_2015_coordination, chalmeau_1995_cooperation}. According to Amici and Bietti~\cite{amici_2015_coordination}, for example, coordination is a fast low-level process of behavioral matching and interactional synchrony which could, but not necessarily, facilitate middle-level processes like cooperation (where some individuals bear certain costs to provide benefits to others) or high-level processes like joint action, which requires other resources like turn-taking and alignment of linguistic resources during dialogue.

If we look at Sebanz and colleagues definition of joint action, it could be considered as a kind of activity based on the usual sense of this term. Thus, some authors use the concept ``joint activity'' interchangeably with ``joint action''~\cite{tollefsen_2005_let,grafenhain_2013_three} while others see the joint activity composed of joint actions~\cite{clark_1996_using, feltovitch_2005_common}. Clark says that ``Joint activities advance mostly through joint actions''. He defines the properties of a joint activity among which there are: it is carried out by 2 or more participants, each participant has a public role or they try to establish and achieve joint goals, and they may have private goals. He also highlights the need for coordination: ``What makes an action a joint one, ultimately, is the coordination of individual actions by two or more people. There is coordination of both \textit{content}, what the participants intend to do, and \textit{processes}, the physical and mental systems they recruit in carrying out those intentions''~\cite[p~.59]{clark_1996_using}. 

In this manuscript, the word joint action will be used to indifferently refer to an activity/task composed of several (joint) actions, \ie a high level joint action or as a single action, but in both cases it will imply that it is a ``social interaction social interaction where two or more individuals coordinate their actions in pursuit of a common goal''~\cite{castro_2020_joint}.

\subsection{Two possible segmentations around Joint Action}

Before going through the mechanisms involved in joint action, we will briefly present two segmentations of joint action: a temporal segmentations, \ie the different phases a joint action goes through, and a cognitive model for human agency \ie the different neurocognitive levels that are involved in joint action. It seemed necessary to present these two segmentations as the processes related to joint action described in Section~\ref{chap1:subsec:necess_ja} are sometimes involved in one phase/level but not in another. However, we will not go through these details as it is not necessarily relevant to the rest of the manuscript.

\subsubsection{Temporal segmentation of Joint Action}
As a joint action is a form of social interaction, it can also be divided in three phases as presented in Section~\ref{chap1:subsec:social_int}: an initiation, a body and a closing~\cite{heesen_2017_social}. Each phase a role; the initial phase establishes among other things the joint commitment, \ie who is to participate, in what roles, what actions will be performed, and when and where they will be performed different roles for the participants~\cite{clark_2006_social}. Then, in the body they coordinate to perform their goal. Finally, ``to complete a joint action, participants first need to arrive at the mutual conviction that they are both indeed ready to terminate it''~\cite{heesen_2017_social}, if they achieved their goal for example.

At a lower level of joint action, the level of action and not social interaction, joint action can be seen as a process with two phases: planning and execution. Curioni \etal{} proposed a model, specifying what happens in each phase~\cite{curioni_2017_joint}: 
\begin{bulletList}
	\item planning: 
	\begin{bulletList}
		\item expectations on partner's intentionality
		\item selecting action possibilities
		\item establishing commitment
	\end{bulletList}
	\item execution:
	\begin{bulletList}
		\item aligning attention to objects and events
		\item maintaining commitment
	\end{bulletList}
\end{bulletList}
\subsubsection{Neurocognitive segmentation of Joint Action}

To describe the levels of the neurocognitive mechanisms involved in joint action, we will base ourselves on the conceptual framework of action established by Pacherie~\cite{pacherie_2008_phenomenology}. This framework is particularly relevant for the rest of manuscript as it has a lot similarities with the three-layered robotic architecture that will be described in Section~\ref{chap2:sec:rob_archi}, as noticed in~\cite{clodic_2017_key}. It is based on a dynamic model of intentions and distinguishes:

\begin{bulletList}
	\item A distal intentions level (D-intentions) in charge of the dynamics of decision making, temporal flexibility and high level rational guidance and monitoring of action;
	\item A proximal intentions level (P-intentions) that inherits a plan from the previous level and whose role is to anchor this plan in the situation of action, this anchoring has to be performed at two levels: temporal anchoring and situational anchoring;
	\item A motor intentions level (M-intentions), which encodes the fine-grained details of the action (corresponding to what neuroscientists call motor representations), is responsible for the precision and smoothness of action execution, and operates at a finer time scale than either D-intentions or P-intentions
\end{bulletList}

This model of action has then been enriched with the specificities of joint action in~\cite{pacherie_2012_agency}, integrating at each levels the representations and processes associated to the joint action partner. We will not go through the details of it here but they will be mentioned all along Section~\ref{chap1:subsec:necess_ja}.

\subsection{What is necessary for Joint Action?}\label{chap1:subsec:necess_ja}

Leaving aside the debate on the concept of joint action, we aim to focus on the mechanisms that enable the consecution of joint actions. What we found to be the mechanism on which every author (or almost) agrees on to say that it is required for a joint action is the \textit{coordination}. This mechanism itself is supported by other cognitive and sensorimotor processes. Also, philosophers introduced another concept involved in joint action which is the \textit{shared intention}. In Figure~\ref{chap1:fig:ja}, we made an attempt to represent, in a non-exhaustive way, a number of these processes and how they are connected to each other.

\begin{figure}[!ht]
	\includegraphics[width=\linewidth]{figures/chapter1/joint_action.pdf}
	\caption{Overview of a non-exhaustive set of processes related to joint action}
	\label{chap1:fig:ja}
\end{figure}

We will first present the concepts of \textit{shared intention} and \textit{joint commitment} and then we will talk about what it is \textit{coordination} and the mechanisms on which it depends. Some concepts are highlighted with italics to show how interrelated there are between them.

\subsubsection{Shared Intention}
First, before coming to the concept of shared intention, what is an intention? We are going to take a look at three definitions, first from a philosopher, then from computer scientists and finally from psychologists. 

Sometimes, we talk about intention to refer to something we do intentionally (action) or to refer to things we intend to do (mental state). Thus, Bratman distinguishes both~\cite{bratman_1984_two} associating the first possibility to what he calls present-directed intention (I may intend to start my car now) and the latter to future-directed intention (I may intend to start my car later today). But, ``when I am starting my car it may seem natural to say that I no longer intend to start it, I am starting it''~\cite[p.~379]{bratman_1984_two}. He chose to concentrate on future-direction intentions rather than present-directed intentions when referring to intentions. 

Cohen and Levesque based their definition of intention on this view of Bratman~\cite{cohen_1990_intention}. They added the notions of commitment and goal: ``An intention is defined as a commitment to act in a certain mental state: An agent intends relative to some conditions to do an action just in case she has a persistent goal (relative to that condition) of having done the action, and, moreover, having done it, believing throughout that she is doing it''~\cite[p.~496]{cohen_1991_teamwork}. 

The definition of Tomasello \etal{} includes the notion of plan since they defined an intention as ``a plan of action the organism chooses and commits itself to in pursuit of a \textit{goal}. An intention thus includes both a means (action \textit{plan}) as well as a goal''~\cite[p.~676]{tomasello_2005_understanding}. 

Now that we have a clearer idea of an intention, we can focus on shared intention. We will start again with Bratman~\cite{bratman_1993_shared}. He considers that two agents have the shared intention to J if and only if: 
\begin{enumerate}
	\item (a) [agent X] intend that [they] J and (b) [agent Y] intend that [they] J.
	\item\relax [agent X] intend that [they] J in accordance with and because of 1a, 1b, and meshing subplans of 1a and 1b; [agent Y] intend that [they] J in accordance with and because of 1a, 1b, and meshing subplans of 1a and 1b.
	\item 1 and 2 are \textit{common knowledge} between [them].
\end{enumerate}

Tomasello \etal{} refer to shared intentionality (``we'' intentionality) and joint intention~\cite{tomasello_2005_understanding}. For them, it refers to collaborative interactions in which participants have a shared goal (\textit{shared commitment}) and coordinated action roles for pursuing that shared goal. This definition is based on the works of Gilbert~\cite{gilbert_1989_social}, Searle~\cite{searle_1983_intentionality} and Tuomela~\cite{tuomela_1995_importance}. Bratman refered to Searle and Tuomela about their definition of ``we-intention'', highlighting the difference with shared intention. ``we-intention'' or ``collective intention'' are intention of an invidual concerning a group's or collective's activity, and there can be such intention even though there is only one individual (falsely believing others are involved)~\cite{bratman_1993_shared}. Whereas a shared intention necessarily involved at least two persons. Thus, for Tomasello \etal, what Bratman calls shared intention, is actually closer to what they call joint intention and not shared intentionality. Indeed, in their view of joint intention, each partner's ``representation of the intention [...] contains both self and other'', as we can see in their illustration, reproduced in Figure~\ref{chap1:fig:ji}. For them, joint intention involves \textit{shared goals} with and coordinated action \textit{plans}. 

 \begin{figure}[!ht]
 	\includegraphics[width=\linewidth]{figures/chapter1/shared_representation.png}
 	\caption{Illustrative example of a collaborative activity by Tomasello \etal~\cite{tomasello_2005_understanding}. Here the humans have for shared goal to open the box together. They choose a means to perform it which takes into account the other capabilities and so form a joint	intention.}
 	\label{chap1:fig:ji}
 \end{figure}

Cohen and Levesque took their inspiration from Bratman's definition of shared intention is their view of joint intention for artificial agents, considering joint intention as a future-directed \textit{joint commitment} to perform a collective action while in a joint (or shared) mental state.

\subsubsection{Joint Commitment}
Commitments can be understood as ``a triadic relation among two agents and an action, where one of the agents is obligated to perform the action as a result of having given an assurance to the other agent that she would do so, and of the other agent’s having acknowledged that assurance under conditions of common knowledge''~\cite[p.~756]{michael_2017_commitment}. Commitments are not necessarily established through promises or even explicit verbal communication~\cite{ledyard_1994_public, scanlon_2000_we, siposova_2018_communicative}, however, this basic definition allows us to see the fundamental component of a commitment. But why are commitments important for joint action?

In philosophy and psychology, many authors have emphasized the importance of commitments for joint action such as Cohen and Levesque~\cite{cohen_1991_teamwork}, Clark~\cite{clark_2006_social}, Gilbert~\cite{gilbert_2009_shared}, Bratman~\cite{bratman_2014_shared}, Michael and Pacherie~\cite{michael_2015_commitments}, Roth~\cite{roth_2014_shared} or Siposova \etal~\cite{siposova_2018_communicative}. 

For instance, in philosophy, Gilbert~\cite{gilbert_2009_shared} and Bratman~\cite{bratman_2014_shared} have largely argued about the requirements for people to establish shared intentions and their role in explaining social coordination. While Bratman has argued that shared intentions can be understood as an aggregation of individual intentions which only requires individual commitments with general standards of rationality, Gilbert has argued that shared intentions are essentially tied to joint commitments. According to her, two or more persons share an intention to do something if and only if they are jointly committed to intend as a body to do it~\cite{gilbert_2009_shared}. In other words, joint actions require the people involved to impose obligations to each other. Further, Roth has argued that joint action requires the participants to be committed to the activity in the Gilbert’s sense, which also implies contralateral commitments that hold across the other participants in the shared activity~\cite{roth_2014_shared}. For instance, if Sue and Jack agree on going for a walk together, they share a commitment to carry out the shared action but also, they assume an individual contralateral commitment to keep pace with each other. In brief, commitments are essential for the establishment of joint and individual intentions during shared activities. 

In psychology, several authors, such as Clark~\cite{clark_2006_social}, Michael \etal~\cite{michael2016} or Siposova \etal~\cite{siposova_2018_communicative}, have studied how implicit and explicit communication are used to establish commitments and their importance for coordinated actions. For example, Clark has emphasized how partners use communicative exchanges like projective pairs, where one of the participants proposes a particular goal to another (Let’s do G! Should we do that?), who then accepts or rejects the proposal~\cite{clark_2006_social}. Those exchanges are pervasive in human-human coordinated actions and they serve to negotiate goals, plans and social roles which are translated into an amalgamate of different types of commitments that are necessary for the execution of the general \textit{joint goal}. Michael \etal{} suggest that people often use investment of effort in a task as an implicit cue for making the perceiver aware that we expect him to behave collaboratively which often triggers a sense of commitment that motivates actions~\cite{michael2016}. Furthermore, Siposova \etal{} have found that humans use implicit cues like gaze signals to communicate an agreement or commitment to carry out a task their partner intends to perform~\cite{siposova_2018_communicative}.

To summarize about joint commitment, we retain the words of Gilbert~\cite[p.~7]{gilbert_2013_joint}: ``a joint commitment is a commitment of the two or more people involved. It is, more fully, a commitment by two or more people of the same two or more people'', keeping in mind that it ``is not the case that [agent X] and [agent Y] are jointly committed if and only if [agent X is] personally committed in some way and [agent Y is] also'' as the agents ``are jointly committed to [J] as a body''.

\subsubsection{Coordination}
Coordination is a central mechanism to distinguish individual actions from joint actions. There has been an important deal of conceptual and empirical work investigating this process, such as the one of Knoblich \etal~\cite{knoblich_2011_joint} and the one of Pacherie~\cite{pacherie_2012_agency}. Coordination relies on several mechanisms, which are not necessarily intentional (emergent coordination~\cite{knoblich_2011_joint}), including for example perception-action matching~\cite{brass_2001_movement}, perception of joint affordances~\cite{ramenzoni_2008_short} or action simulation~\cite{sebanz_2009_prediction}. As for intentional coordination – sometimes referred to as planned coordination~\cite{knoblich_2011_joint} –, it requires the partners: (i) to represent their own and others' actions, as well as the consequences of these actions, (ii) to represent the hierarchy of sub-goals and sub-tasks of the plan, (iii) to generate predictions of their joint actions, and (iv) to monitor the progress toward the joint goal in order to possibly compensate or help others to achieve their contributions~\cite{pacherie_2012_agency}. From Section~\ref{chap1:subsubsec:shared_rep} to Section~\ref{chap1:subsubsec:coord_smooth}, we present a non-exhaustive set of mechanisms on which relies coordination. We chose the ones that seemed: to be the most mentioned in the philosophy and psychology literatures, to obtain consensus about their involvement in coordination and to be relevant to Human-Robot Interaction. 

\subsubsection{(Shared) Representations}\label{chap1:subsubsec:shared_rep}
As stated by Sebanz \etal, joint action depends on the ability to share representations~\cite{sebanz_2006_joint}. Representation sharing is present at different levels, \ie agents can share representations of objects, events, actions, goals, plans and tasks~\cite{pacherie_2012_agency,vesper_2017_joint}. These representations enable, among other things, the prediction (see Section~\ref{chap1:subsubsec:pred}) of other's actions. 

\paragraph{Representation of (Shared) Tasks}
A task can be described at multiple grains or levels of abstraction~\cite{cooper_2000_contention},  the same action can be described
as both ‘putting a piece of toast in one’s mouth’ and ‘maintaining an adequate supply of nutrients’. A used definition in psychology is that ``a task consists of producing an appropriate action (\eg conveying to mouth) in response to a stimulus (\eg toast in a particular context)''~\cite[p.~1]{monsell_2003_task}. Sebanz \etal{} extended this definition with the possibility to execute more than one action when responding to a stimulus~\cite{sebanz_2005_two}. 

How to share a task? Sebanz \etal{} proposed that ``sharing a task representation or corepresenting a task then means that an individual represents at least one rule that states the stimulus conditions under which a coactor should perform a certain action''~\cite[p.~1235]{sebanz_2005_two}.
In another paper, in the context of joint action, Sebanz \etal{} evoked studies showing the formation of shared representations during collaborative tasks, \ie an agent knows what the other should do and represents it in a functionally equivalent way to their's own. They concluded that it allowed individuals ``to extend the temporal horizon of their action planning,
acting in anticipation of others’ actions rather than simply responding''~\cite[p.~73]{sebanz_2006_joint}.


\paragraph{Representation of (Shared) Goals}
Goal has two meanings leading sometimes to ambiguities: the state-to-reach of the environment (external goal) and the mental representation of a desired state (internal goal)~\cite{tomasello_2005_understanding}. It is interesting to be aware of this double meaning. 

Several authors highlighted the need of the representation of a shared goal for joint action such as Pacherie~\cite{pacherie_2012_agency}, Tomasello \etal{}~\cite{tomasello_2005_understanding} or Cohen and Levesque~\cite{cohen_1991_teamwork}. Sometimes they use the terms  common goal~\cite{searle_1990_collective}, joint goal or joint persistent goal.
Based on Braman~\cite{bratman_1992_coop}, Tomasello \etal{} affirmed that ``there is a shared goal in the sense that each participant has the goal that we (in mutual knowledge) do X together'' and that ``each interactant has goals with respect to the other’s goals''~\cite{tomasello_2005_understanding}. Pacherie listed as a condition for joint action that each agent has to represent their goals and their coagents goals~\cite{pacherie_2012_agency}.

\paragraph{Representation of (Shared) Plans}
A intention is sometimes defined as a plan of actions that an agent chooses to achieve a given goal~\cite{tomasello_2005_understanding, kaplan_2006_challenges}. 
As for shared goals, Tomasello \etal{} and Pacherie highlighted the need for an agent to represent ``their own subplans and the meshing parts of the subplans of others, and some of what they represent is to be performed by others''~\cite[p.~353]{pacherie_2012_agency}.

Representations of plans and shared plans are more studied by computer scientists than by philosophers and psychologists, proposing computational models that we will not present here. Grosz and Kraus demonstrated that shared (collaborative) plans should not be treated as the sum of individual plans but as plans necessitating from the agents joint intentions, a mutual belief of how to perform the task and eventually individual or shared plans to perform the task's actions~\cite{grosz_1996_collaborative}.

\paragraph{Representation of Actions and Effects}
Studies showed that when an agent observes an action, a corresponding representation in their action system is activated~\cite{rizzolatti_2004_mirror}. Sebanz \etal{} affirmed that representation sharing is essential to joint action, specially action representations, as ``individuals could be ‘on the same page’ action-wise by sharing representations of actions and their underlying goals''~\cite[p.~71]{sebanz_2006_joint}. Pacherie evokes the need of agents to have the ability to have not only a representation of actions to be performed, self's and other's, but also their consequences~\cite{pacherie_2012_agency}. 

\paragraph{Affordances}
The concept of affordances has been introduced in 1966~\footnote{\url{https://www.merriam-webster.com/dictionary/affordance}} by Gibson, a psychologist, who presented his theory in~\cite{gibson_1979_theory}. He coined the term to refer to what the environment has to offer to the animal (individual), ``what it provides or furnishes, either for good or ill''. Then, the term and concept became popular and have been used in other fields than the original one (ecological psychology) such as cognitive psychology, human-computer interaction or design. Osborne discussed in his thesis~\cite{osborne_2014_ecological}, among other things, the history of the word and the different uses and meaning there are nowadays (see also two reviews on affordances~\cite{jamone_2016_affordances, bach_2014_affordance}). The definition that is commonly used in HCI/HRI has been introduced by Norman, a design researcher, in 1988 which claimed that ``affordance refers to the perceived and actual properties of the thing, primarily those fundamental properties that determine just how the thing could possibly be used''~\cite[p.~9]{norman_1988_psychology}. Thus, it became associated to the term \textit{action possibilities}. 

What about affordances when people are in a joint action? Richardson \etal{} showed that when acting together, people take into account not only their motor affordances but also the ones of their partners, helping to decide whether to perform a joint action or an individual action with an object~\cite{richardson_2007_judging}. Thus, Knoblich \etal{} called \textit{common affordance} ``when two agents have similar action repertoires and perceive the same object [will likely] engage in similar actions because the object affords the same action for both of them''~\cite[p.~63]{knoblich_2011_joint}, enabling coordination as agents perceive the same objects at the same time. They called \textit{joint affordance} when ``objects have an affordance for two or more people collectively [(a two-handled saw)] which is not necessarily an affordance for any of them individually''.


\subsubsection{Joint Attention}\label{chap1:subsubsec:joint_att}
We will start with two complementary definitions of \textit{attention}. The first one is from Tomasello \etal{} who say ``attention may thus be thought of as intentional perception (selective attention)''~\cite{tomasello_2005_understanding}. The second one is from Kaplan and Hafner~\cite{kaplan_2006_challenges} who define attention as ``the temporally-extended process whereby an agent concentrates on some features of the environment to the (relative) exclusion of others''. They distinguish to situations for which the process can occur: passive attention when a salient event happens and thus automatically triggers the attention of the agent, and active attention the agent is involved in an
intentionally directed process and must actively select particular features of its environment. 

What happens to this process in the context of a joint action? We then talk about \textit{joint attention}. To perform a joint action, partners need a common goal. Indeed, joint action requires that individuals plan and perform their actions according to their predictions about the other’s actions to reach this goal. Joint attention is a key feature for this purpose, playing a crucial role in ``being and acting together''~\cite{tomasello_2009_cultural}, as it allows the partners to establish and share a perceptual common ground, necessary to initiate the joint action but also for individuals already engaged in a joint action to coordinate successfully. 

Despite this agreement to affirm that joint attention is important for joint action, Siposova stated that ``there is still surprisingly little agreement on exactly what joint attention is and how it is achieved''~\cite{siposova_2019_new}. While for some authors, two agents orienting their attention towards the same referent is a sufficient criterion to speak about joint attention~\cite{butterworth_1991_minds}, others like Pacherie precised that ``the phenomenon of joint attention involves more than just two people attending to the same object or event''. A classic way to define joint attention is the ability to coordinate our attention to the same object of interest (\eg as shown by Bakeman and Adamson~\cite{bakeman_1984_coordinating}), enabling us to integrate others’ attentional focus and therefore to experience the world together as described by Tomasello~\cite{tomasello_2009_cultural}.  ``The attentional focus of the two persons must be truly joint in the sens that both participants are \textit{monitoring} the other's attention to the outside entity'', thus joint attention cannot exist without mutual knowledge~\cite[p.~106]{tomasello_1995_joint}.

To complete this view of joint attention, we can mention Carpenter and Liebal that highlighted the need (1) to develop mutual knowledge of this coordinated attention, and (2) to represent the other agent’s intentional states~\cite{carpenter_2011_joint} or Kaplan and Hafner that make the notion of \textit{goal} appear in their definition, describing joint attention as (1) a coordinated and collaborative coupling between intentional agents where (2) the goal of each agent is to attend to the same aspect of the environment~\cite{kaplan_2006_challenges}.

Joint attention can either be explained with basic learning mechanisms -- lean joint attention -- or as ``the result of particular cognitive operations or second-order representational competencies''~\cite{racine_2011_getting}, \ie what Tomasello and Carpenter called socio-cognitive abilities of shared intentionality~\cite{tomasello_2007_shared} -- rich joint attention. Kaplan and Hafner noticed in 2006 that current research in HRI about joint attention tended to focus on ``surface behaviors'', like simultaneous looking or coordinated behaviors~\cite{kaplan_2006_challenges} which corresponds to lean joint attention.\todo{check si evolution depuis 2006}

Finally, sometimes it is possible to see references to ``shared attention'' is the literature, which can be confusing for the reader when no precision or definition is given. Some authors use the two words interchangeably, while some consider that there is a difference between both. There are especially two works mentioning this fact and making a distinction, the one of Emery~\cite{emery_2000_eyes} and a bit later the one of Triesch \etal~\cite{triesch_2006_gaze}. They define joint attention as two people having the same focus of attention while they define shared attention as a more complex form of communication where each agent knows on what the other agent is focused. We can notice that it is quite similar to the definitions of joint attention we gave above.

\subsubsection{Common Ground}
Common ground, or common knowledge or mutual knowledge, or mutual belief, these are the words to refer to the same general idea -- used by some authors interchangeably~\cite{clark_1992_arenas, clark_1996_using} -- but sometimes with nuances like for joint attention. Lewis, a philosopher, claims that a proposition P is commonly known among two agents if the proposition is known by the two agents and both agents know that agent A can draw the same conclusions from P that agent B can and vice-versa.~\cite{lewis_1969_convention}. In another famous formulation of philosophers~\cite{schiffer_1972_meaning} and psychologists~\cite{thomas_2014_psychology}, common knowledge must be understood as the recursive belief in which S knows P, Y knows P, S knows that Y knows P, Y knows that S knows P, S knows that Y knows that S knows P, and so on. The subject does not necessarily represent the whole line of reasoning beforehand but should be able to infer it. Thus, we can assume that from the individual point of view, common knowledge or common ground is the information that one may reasonably assume that one and her partner know and they can also know or infer that the other knows. For our purpose, such information may include goals and sub-goals, intentions (see~\cite{bratman_1992_coop}), ways to proceed, facts on the environment (see joint attention in Section~\ref{chap1:subsubsec:joint_att}), appropriate scripts and roles, and any other type of information necessary or relevant for the joint action. Cohen and Levesque, computer scientists, consider mutual knowledge about a \textit{joint persistent goal} P, such as ``it is true (and mutual knowledge) that until they come to mutually believe that P is true, that P will never be true, or that [the condition] Q is false, they will continue to mutually believe that they each have P as a weak achievement goal relative to Q and with respect to the team''~\cite[p.~499]{cohen_1991_teamwork}.

\subsubsection{Monitoring}
An agent can monitor multiple things related to a task: a goal, an action, a task-progress, mistakes, another agent, an object... Vesper \etal{} showed that a agent typically monitor the task-progress in order to determine whether the current state of the joint action and the desired outcome are aligne~\cite{vesper_2010_minimal}. Pacherie named the monitoring of the progress towards the joint goal as a condition for agent to share a proximal intention~\cite{pacherie_2012_agency}. Monitoring the task-progress is not enough. An agent also needs to monitor its partner, especially through joint attention that we presented in Section~\ref{chap1:subsubsec:joint_att}, as attention is a monitoring process and joint attention can be seen as the co-actors’ ability to monitor each other’s gaze and attentional states~\cite{emery_2000_eyes}. Then, it is also closely related to the shared representations we presented in Section~\ref{chap1:subsubsec:shared_rep}. Indeed, shared task representations enables the monitoring of the individual actions~\cite{knoblich_2011_joint}. Sebanz \etal{} mentioned ``action observation'' which seems to be an equivalent to the term monitoring\footnote{https://www.merriam-webster.com/thesaurus/monitoring}. Action observation and thus monitoring is based on action representations and allows to predict (see Section~\ref{chap1:subsubsec:pred}) what others are going to do next~\cite{sebanz_2006_joint}. Finally, ``monitoring is useful to detect mistakes or unexpected outcomes in one's own or one's partner's performance, enabling one to quickly react and adapt accordingly''.

\subsubsection{Action Simulation}
Sebanz \etal{} highlighted the need of action simulation for agents to coordinate~\cite{sebanz_2009_prediction,knoblich_2011_joint}. Action simulation is the process allowing an agent to predict the timing and outcomes of the given action, by observing the action and applying predictive models of the action in their motor system. Thus, an agent can predict other agents' actions in real time~\cite{wolpert_2003_unifying}.

\subsubsection{Predictions}\label{chap1:subsubsec:pred}
For Pacherie, there are three types of predictions: self-predictions, other-predictions, joint predictions. Self-predictions are the predicted consequences of the agent's own actions. Other-predictions are the actions, goals, motor and proximal intentions of their coagent and their consequences. Joint predictions are the agents' prediction of the joint effects of their own and others' actions. These predictions allow agents to ``decide on their next moves, including moves that may involve helping others achieve their contributions to the joint goal (triadic adjustment)''~\cite[pp.~354-355]{pacherie_2012_agency}. Sebanz \etal{} support the same idea, claiming that predictions, based either on action observation or on shared representations, ``allow one to prepare actions in responses to events''~\cite[p.~73]{sebanz_2006_joint}.

\subsubsection{Coordination Smoothers}~\label{chap1:subsubsec:coord_smooth}
Coordination smoothers, as their name implies, are one way to facilitate coordination. They are defined as the changes in an agent own behavior to ease the interaction with another one~\cite{vesper_2010_minimal}. For example, an agent may exaggerate their movements, making them easier to predict for their partner. The change of behavior may concern not only one's own behavior but also the use of objects according to their affordance. Coordination smoothers can be produced automatically such as a nod or be intentional~\cite{michael_2015_commitments}.


\subsection{Communication}\label{chap1:subsec:comm}
An important part of human psychological devices involved in joint action is communicative, serving different purposes – \eg negotiating, guiding, questioning~\cite{austin_1962_how, clark_1992_arenas, sperber_1995_relevance} and leading to mobilize different types of information. This flexibility allows us to provide information about the relevant objects involved in a task, but also about the emotional or cognitive states of the participants. 

Sometimes, people are in situations where social norms, conventions, or scripts are available to regulate our social interactions~\cite{schank_1977_scripts,andrews_2012_apes, castro_2020_social}. For instance, as customers, we usually know how to interact with a waiter in a restaurant because the parties involved know some clear rules of etiquette, social norms and knowledge of how to proceed that regulate the interaction to achieve the joint goal of having a meal. However, even when these rules and norms exist, human interactions require signaling and communicating different types of information regarding the initiation, maintenance, or the exit of joint action, the acknowledgment of roles assignation, or specificities regarding preferences, goals, and subs-tasks. 

According to Michael and Pacherie, participants can face three sources of uncertainty during joint action, which can overlap and influence each other~\cite{michael_2015_commitments}. First, motivational uncertainty refers to the uncertainty of not knowing whether or not the partner is motivated to engage in the overall joint action, a particular goal, or sub-goal, or her degree of motivation. Second, instrumental uncertainty refers to the state of not knowing the other participant’s instrumental beliefs on how to proceed, \ie which roles to assume or when and where to act. Finally, common ground uncertainty emerges when instrumental beliefs and motivations are not mutually manifested. Thus, even if the participants share a goal or agree on how to proceed, they might not know that this is the case. Any communicative act or strategy is directed to reduce common ground uncertainty, making mutually manifest a piece of information that can involve instrumental or motivational states, aspects of the environment, goals, or other relevant information for the consecution of the joint action. In a minimal sense, then, communicative strategies can be defined as overt stimuli generated to activate, add up or update the common ground and knowledge related to a particular joint action. 

The recognition of the other as a potential partner for joint action can be carried out by verbal and/or non-verbal communicative cues, which can be more or less explicit at different stages of the interaction. The inferential processes at play in such context have originally been explored in the frame of pragmatic theories, in particular through the notions of relevance~\cite{sperber_1995_relevance} or Grice’s maxims of conversation~\cite{grice_1989_studies}.

Interestingly, humans often establish communicative strategies to facilitate information exchange before the joint action itself. The establishment of \textit{mutual recognition} is fundamental for the initiation of the joint action but also strongly influences its deployment. For instance, establishing mutual recognition facilitates the assignment of roles, which also determines the communicative strategies used during the execution of the action. 

\paragraph{Verbal} One can engage in communication employing so-called \textit{recognitives} or \textit{observatives}, speech acts whose main function is to call another person’s attention upon herself, or other aspects of the context in order to make her aware that recognition is in place. 

An example of recognitives is \textit{vocatives}, like greetings that are precisely used to call a person upon herself. Vocatives can enable mutual recognition and facilitate role assignment in some contexts (\eg ``Welcome to our restaurant!" in the previous example). Moreover, vocatives are often followed by other speech acts like questions that can help to set the sub-tasks or goals of the joint action (\eg ``What can I do for you today?''). Another example of recognitives is acknowledgments, whose function is to make the other aware that you recognize or take on what they say (\eg answering ``thank you'' to the vocative ``welcome''). They allow individuals to acknowledge each other's recognition and to ensure the fact that joint action will take place is mutually shared. 

The other types of speech act relevant for mutual recognition are observatives, which serve to identify a potential joint goal by directing the other’s attention toward a specific object or event in the near environment. For instance, imagine two hunters searching for prey; when one calls the other ``Hey, a deer!'', they can start coordinating to capture the animal. Such speech acts can facilitate the recognition of the other as a potential partner for the joint action and then trigger the set of expectations and anticipations necessary to coordinate and perform the action.

\paragraph{Non-verbal} \textit{Joint attention} is a kind of communication process, as explained in Section~\ref{chap1:subsubsec:joint_att}, it allows the partners to establish and share a perceptual common ground.

We can also find non-verbal modalities of communication analogous to recognitive or observatives. For instance, communication can stem from subtle cues like the mere reaction to the presence of the other with a frown movement or the search for eye contact. As Brinck and Balkenius~\cite{brinck_2018_mutual} argue, by making eye contact, one individual is attending to the other attending to the first, which can implicitly be regarded as a joint commitment to interact in most social contexts. Likewise, acts of acknowledgements can be performed non-verbally as well: people often direct each other's attention toward external objects or events through non-verbal reference, whether it involves vocalizations, gestures, and/or gazing~\cite{bates_1979_emergence, leavens_2004_referential, brinck_2008_role}. Non-verbal reference includes four essential actions: a \textit{preparatory behavior} that draws the observer’s attention to the sender, a \textit{communicative-intent indicating behavior} to signal the sender’s attempt to share attention and interact face-to-face with the observer; a \textit{referential behavior}, to orient the other’s attention in the direction of the target object or event; and an \textit{essentially intentional behavior} that orients back the attention to oneself to make sure they understand the act~\cite[p.~122-123]{brinck_2008_role}.

To illustrate non-verbal communication during the execution of joint action, we can take the example of the a study on the exaggeration of behavior. In Sacheli \etal{} experiments (see also Vesper and Richardson~\cite{vesper_2014_strategic}), for instance, two participants had to synchronously grasp an object in an imitative vs. complementary way, each by acting as a Leader or a Follower. The results showed that when acting as leaders, participants tend to give information to their partners about the action to be performed by accentuating some kinematic parameters and reducing the variability of movements, then increasing their predictability by the follower. 


\section{When the interaction goes wrong}
Until now, we have seen the elements facilitating or essential to joint action, but what happens when things go wrong? Things might go wrong because of an error, a mistake, a slip...These words may look like synonym but we can actually make a distinction between them. In this section, we will present of of the classification that has be done. Then, another subject to take interest to is: there's been something wrong but how to repair now?

\subsubsection{Error classification}
Reason published a book entitled Human error~\cite{reason_1990_human}, basing his work, among other things, on Norman~\cite{norman_1981_categorization} and Rasmussen~\cite{rasmussen_1982_human}. He classified errors into three categories: \textit{slips}, \textit{lapses} and \textit{mistakes}. All of them are considered as failures. Additionally to these three, he established another kind of failures: the \textit{violations}, which are not errors. He defined slips as attentional failures, \ie it can be because the agent has been inattentive to the action, not doing the right attentional monitoring (\eg to take the wrong object and not the one they intended to take). It generally happens with frequently performed actions. Lapses are memory failures, \ie an agent forget to perform their action (\eg to go get an object in a shelve and not go back with it because something felt and disturbed the agent). The last type of errors is mistakes, being intentional failures. They happen when an agent choose an action to perform but it is not the appropriate one to reach their goal. Finally, violations are considered as failures but not as errors, being intentional transgression of a rule or a procedure. This classification is illustrated with Figure~\ref{chap1:fig:err}.

 \begin{figure}[!ht]
 	\includegraphics[width=\linewidth]{figures/chapter1/reason-errors.pdf}
 	\caption{Summary and simplification of the failure classification (Generic Error-Modelling System (GEMS) and violations) developed by Reason~\cite{reason_1990_human}. (Illustration by Kathleen Belhassein)}
 	\label{chap1:fig:err}
 \end{figure}


\subsubsection{Repair strategies}
In psychology or philosophy, there are not a lot of works on what happens once an error has been made during a joint action. Conversation Analysis investigated repair, which is a way to correct a misunderstanding or an error during an interaction or an action. The ability to engage in repair is essential in interaction: errors and misunderstandings are likely to arise and must be corrected if the  goal of the interaction is to be successful. Generally, they are classified in four categories in CA \cite{schegloff_1977_preference,wooffitt_2008_conversation}:
\begin{bulletList}
	\item Self-initiated self-repair: Repair is both initiated and carried out by the responsible of the trouble
	\item Other-initiated self-repair: The responsible of the trouble takes care of the repair himself but the trouble have been pointed out by the other
	\item Self-initiated other-repair: The responsible of the trouble signals that a repair is needed and get the other one to repair (\eg he forgot a name and asks for help to remember)
	\item Other-initiated other-repair: The one not responsible of the trouble initiates and carries out the repair. This is closest to what is conventionally understood as ``correction''.
\end{bulletList}

\section{Human-Robot Interaction and Joint Action}\label{chap1:sec:hri_ja}
The study of human-human joint action is important to understand how to make robots better companions and partners for humans. However, it does not mean that they should imitate humans, as they are machines, they have their own abilities and have to develop their own strategies~\cite{bradshaw_2017_human} (\eg displaying arrow on the floor while navigating~\cite{chadalavada_2015_mind, coovert_2014_spatial}).

In the context of the JointAction4HRI project, a non-exhaustive review of existing robotic systems integrating but also recognizing in humans joint action mechanisms has been done, focusing on joint attention, communication to facilitate coordination, repairs strategies and commitments.

\subsection{Joint Attention in HRI}
Joint attention is essential to joint action (see Section~\ref{chap1:subsubsec:joint_att}). Some authors showed that a robot initiating (\ie triggering the attention focus of the partner on the object of interest)~\cite{imai_2003_physical}, responding to (\ie gaze following of the partner's gaze or gesture)~\cite{yu_2010_investigating}, and ensuring joint attention (\ie monitoring of the other's attention)~\cite{huang_2010_joint} improves the task performance and is perceived as more natural. Thus, human pointing gesture recognition as been investigated such as in~\cite{nickel_2007_visual} or eye-gaze signaling(\eg \cite{staudte_2009_visual} or see review~\cite{admoni_2017_social}).

\subsection{Communication to Facilitate Coordination in HRI}

As seen in Section~\ref{chap1:subsec:comm}, communication is important for joint action. It is useful to negotiate, guide, question or realign the beliefs between agents as divergences might occur~\cite{cohen_1991_teamwork}. Here, we will see how robot can do to communicate and understand communication about their internal state or the human partner one, and about intentions.

\paragraph{Internal state communication -- Expressions}
It is not always obvious for the human to know what the robot is ``thinking'', \ie to know in what state is the robot. The robot also needs to be able to recognize human internal states, emotins. Roboticists developed different ways to do so. We found that robot communicating their internal state using lights, dialogue, gestures/moves or facial expressions has been developed. Some of them are also able to analyze human face or voice to detect their emotion or expression. Kim and Kwon designed a robot using all these features to generate expressions according to its knowledge about the task execution state~\cite{kim_2010_computational}. Expressions are generated based on as set of criteria. For example, when the robot computes that it is in unexpected state, it generates surprise. Moreover, they endowed the robot the ability to discriminate between the human partner's happiness, sadness and anger. In the same spirit, we can find a robot recognizing and generating expressions through voice, in relation to the task state and goal~\cite{scheutz_2006_utility}. Finally, we have to mention the work of Breazeal which investigated a lot display of emotions/expressions in human-robot interaction. We can distinguish two types of communication: (1) a robot, which has a caregiver, has a motivation system to regulate the interaction intensity of its caregiver allowing it to express eight emotions with facial expressions~\cite{breazeal_1998_motivational, breazeal_2004_function}, (2) a robot has the ability to recognize four communication intent (approval, attentional bid, prohibition, soothing) and to react to them through speech~\cite{breazeal_2002_regulation, breazeal_2003_emotion}.

\paragraph{Communication of intentions} As explained in Section~\ref{chap1:subsubsec:coord_smooth}, coordination smoothers facilitate the prediction and legibility of a partner's action. Investigation about how the robot could communicate its intention during navigation has been done. Some authors chose to have the robot communicating its intention using lights~\cite{szafir_2015_communicating}, comparing this method with a communication using the head orientation and finding it better~\cite{may_2015_show}. Others worked on make the robot navigation legible, improving its predictability by the human~\cite{dragan_2013_legibility, alami_2006_toward}. A last method to communication navigation intention is by projecting arrows on the floor as well as a map~\cite{chadalavada_2015_mind, coovert_2014_spatial}.  Not only robot navigation should be legible but also its gestures, when handing over an object to the human~\cite{sisbot_2012_human}, or opening a door~\cite{takayama_2011_expressing} for example. Finally, a lot of works can be found on human gestures recognition so the robot could prediction human's action intentions (\eg\cite{barros_2017_dynamic, chang_2018_effects}).


\subsection{Failures in HRI}
Honig and Oron-Gilad studied the different types of failures that could happen during a human-robot interaction and proposed a classification of these~\cite{honig_2018_understanding} based on a meticulous review, illustrated with Figure~\ref{chap1:fig:err_hri}.

\begin{figure}[!ht]
	\includegraphics[width=\linewidth]{figures/chapter1/failures_hri.jpg}
	\caption{Classification of failures in HRI, realized by Honig and Oron-Gilad~\cite{honig_2018_understanding}.}
	\label{chap1:fig:err_hri}
\end{figure}

\subsubsection{Communicating about Failures}
When something unexpected happens during the interaction, either because of a human failure, a robot failure or an external event, robots might need to communicate about it. We saw three most common ways to communicate about a failure: facial expressions and speech. We can notice a less common way proposed by Kwon \etal{} which developed a robot communicating about its incapability to execute a manipulation tasks thanks to the execution of an ``attempt motion'', expressing what it cannot do and why to its human partner (\eg lifting its elbow to communicate that it is trying to lift the cup, but the cup is too heavy for it)~\cite{kwon_2018_expressing}. 

\paragraph{Facial expressions} Breazeal and colleagues investigated the expression of the robot's confusion through facial expressions. For example, in~\cite{breazeal_2002_regulation, breazeal_2003_emotion} humans take into account the robot expressive feedback to assess when the robot ``understand'' them. If the wrong expression appeared, they often speak in an exaggerated way to correct the ``misunderstanding''. Hamacher \etal{} developed a robot  displaying a facial expression after having dropped an egg when preparing an omelet with a human~\cite {hamacher_2016_believing}. Reyes \etal{} proposed a robot displaying a negative facial expression when an error occurs~\cite{reyes_2015_positive}. In work by Silva \etal, the robot decision-making and error detection/handling processes are influenced by the perceived human emotions and the robot can display facial expressions when the human persists in a error~\cite{silva_2016_combining}.

\paragraph{Speech} Most of the time, when speech is involved, it is not only to communicate about the failure but also to initiate a repair strategy. 

\subsubsection{Robot Repair Strategies}
To communicate about a failure is not enough to be able to continue the task or the interaction. A collaborative robot needs repair strategies. Some authors proposed simple strategies while some others developed more complex ones. In~\cite{li_2006_computational}, when the robot detects a failure in its understanding of the human utterance and gesture, it triggers its repair mechanism that leads the robot to ask questions to the human in order to help it disambiguate the utterance/gesture. In~\cite{morales_2019_interaction}, there were two possibilities when a failure happened: the human had an ``assistance opportunity'' (\ie failure case that caused no risk to person or property) before the failure occurrence or not. People were more willing to help the robot in case of failure with an assistance opportunity. Knepper \etal{} proposed a robot, when encountering a failure, able to request help from a human -- which might not be aware of the context. After receiving help, it resumes its autonomous task execution~\cite{knepper_2015_recovering}. Lee \etal{} compared three recovering strategies after a robot failure (but based on videos and not a real robot) to see which one was preferred by the humans: (1) apology (\ie robot apologies for service failure), (2) compensation (\ie robot provides compensation, such as an exchange, a refund, or a discount coupon), (3) option (\ie robot provides human with alternative actions to achieve their goals)~\cite{lee_2010_gracefully}. All strategies had a positive effect (even if not the same). Spexard \etal{} developed three repair strategies according to the type of failure for their robot: (1) when the robot encounters an internal issue, it informs the human about the break-down and asking them a reboot or to contact a technician, (2) it can generate appropriate speech related to error messages from its sensor, \eg the robot informs the human of the reason why it can not move and asks them for help, and (3) the robot asks for a reset if it thinks that the information it has about a human does not seem to be right~\cite{spexard_2008_oops}. Mutlu \etal{} performed a user study to compare three repair strategies in a task where the robot gives instructions to the human in an assembly task~\cite{mutlu_2013_coordination}. The strategies are: (1) ``no repair'' (\ie the robot detects an error but waits without answering to the human's questions), (2) ``simple repair'' (\ie the robot answers by yes or no to the human yes/no questions, for other questions it repeats the instruction), and (3) ``humanlike-repair'' (\ie the robot gives the appropriate information to human, triggered either by a human request, or failure or hesitancy detection). The last strategy was the preferred one by the participants.



\section{Architectures for Collaborative Robots, Decision and Execution}\label{chap1:sec:archi}
\sectionmark{Architectures for Decision and Execution}

Robots are machine which need to perceive, decide and act. There are multiple ways to endow a robot with such abilities, with different levels of complexity. When a robot has a complex and generic software architecture, based on models which might be inspired from other fields like psychology, philosophy, neurology, it is referred to as cognitive robot or autonomous robots or intelligent robot...We are interested in such architectures but designed to be implemented in collaborative robots. And, we take an interest in a particular function of these architecture: the decision-making, the supervision of the task, of the interaction.

\subsection{Architectures for Collaborative Robots}\label{chap1:subsec:archi}
``An integrated cognitive architecture can be defined as a single system that is capable of producing all aspects of behaviour, while remaining constant across various domains and knowledge bases''~\cite[p.~104]{chong_2007_integrated}. Kotseruba and Tsotsos reviewed cognitive architectures starting 40 years ago until nowadays. They accounted around three hundred of them and chose to focus their review on 84~\cite{kotseruba_2020_40}. However, the term \textquoteleft cognitive architecture\textquoteright{} often refers to an architecture modeling human cognition and what interest us is to endow robots with cognitive and interactive abilities, not always basing ourselves on human cognition.  

Some cognitive architectures such as ACT-R has been adapted for human-robot interaction (ACT-R/E)~\cite{trafton_2013_act}. The architecture aims at simulating how humans think, perceive and act in the world, strongly based on theory of mind. It is interesting but to understand humans is not enough to make the robot a good collaborators for them, as it lacks abilities concerning the human-aware task and action execution. 

A very complete architecture, CRAM, dealing with problems such as manipulation, perception, plans or beliefs management has been developed by Beetz \etal~\cite{beetz_2010_cram}. However, this architecture is more designed for a robot acting alone than a robot acting in collaboration with a human.

The work of Scheutz and colleagues is compelling, as they proposed a generic architecture, DIARC, for cognitive robots collaborating with humans~\cite{scheutz_2006_utility,scheutz_2019_overview}. In this context, it handles perception, dialogue and different kind of actions. But, there are not real modeling and taking into account of the human at each level of the architecture.

Another architecture worth to be mentioned is the DAC-h3 architecture by Moulin-Frier, Fischer \etal, inspired from biology~\cite{moulin_2017_dac}. It is designed for a robot maintaining social interactions with humans, able to tell narratives and to acquire knowledge thanks to its interactions with humans. As it is mainly dedicated to knowledge acquisition and expression, it lacks planning and execution abilities.

Finally, there is the architecture developed and implemented by Lemaignan and colleagues for collaborative robots. All deliberative components of the architecture are human-aware~\cite{lemaignan_2017_artificial}, \ie all of components except the sensorimotor layer. This architecture is based on the philosophical BDI model developed by Bratman~\cite{bratman_1987_intention,bratman_1988_plans}. It has 3 main concepts defined as the following in computer science:
\begin{itemize}
	\item \textit{Beliefs}: They are a representation of the agent’s knowledge about the world. ``[They] can be viewed as the informative component of system state''~\cite[p.~313]{rao_1995_bdi}. It is not the word ``knowledge'' that has been chosen to define this concept because what the agent perceives of the environment is in fact the likely state of the environment. There is no certainty, its sensors are not accurate or could malfunction. This way of distinguish knowledge and beliefs is one that can be found in the literature of distributed computing~\cite{lamarre_1994_knowledge}.
	\item \textit{Desires}\footnote{In one of the first implementation, PRS, ``Goals'' notion was used instead of ``Desires''~\cite{georgeff_1989_decision}, then they use it in a interchangeable way in~\cite{georgeff_1991_modeling} and finally choose ``Desires''~\cite{rao_1995_bdi} with the definition given in the AI literature, \eg desires can be many at any instant and may be mutually incompatible. Therefore, a goal will be a chosen desire~\cite{cohen_1990_intention} and concurrent goals are consistent.}: They are a representation of the motivational state of the system. They provide ``information about the objectives to be accomplished or, more generally, what priorities or payoffs are associated with the various current objectives''~\cite{rao_1995_bdi}. 
	\item \textit{Intentions}: They are a representation of the currently chosen course of action (plan). It is the deliberative component of the system. The selected course(s) of action are determined with a deliberative function, according to the beliefs and desires~\cite{rao_1995_bdi}.
\end{itemize}


\subsection{Supervision for Human-Robot Interactions}
The supervision component is the binder of a robotic architecture. Without it, there is no task, no interaction happening. Indeed, what we define by `supervision' is the higher level of the architecture, the process involving decision-making, eventually based on plans, and action execution and monitoring. When speaking about joint action, we think it is the component that should handle coordination, communication, monitoring, repair strategies and eventually joint attention and common ground alignment, based on shared representations.

We can find in the literature multiple works proposing components with a part of these features. The ones that we will present have been a source of inspiration, from far or close, for the contributions of this manuscript. We will start with the oldest one, Shary, which has been developed in our laboratory. It is a component dedicated to supervision for human-robot interactions, with a strong emphasis on communication, allowing to execute shared plans and to monitor human and robot actions~\cite{clodic_2009_shary}. Chaski is a task-level executor, focusing on coordination and decision-making. It takes as input shared plans with deadlines and minimize the human idle time when executing of this plans~\cite{shah_2011_improved}. There is also Pike an online executive that unifies intention recognition and plan adaptation to deal with temporal uncertainties during Shared Plan execution~\cite{karpas_2015_robust}. G\"{o}r\"{u}r and colleagues developed a robot able to handle unexpected human behavior, the first one being the human doing an action irrelevant to the task and the second one being the human not wanted the robot assistance~\cite{gorur_2017_toward, gorur_2018_social}. For this, they developed a human model and have a monitoring of human's actions and endow the robot with the abilities to be reactive and proactive. Similarly, Baraglia \etal{} proposed a reactive and proactive robot, being able to help when requested by the human or when detected~\cite{baraglia_2017_efficient}. Iocchi \etal{} presented a framework which generate and execute robust plans for service robots~\cite{iocchi_2016_practical}. It allows to not explicitly represent all possible situations would face (\eg low battery means the robot should not navigate) and also to face unpredicted situations where an action failed with no alternative solutions. They implemented it by separating the state variables needed at both planning and execution and the one needed at execution time only. Finally, Devin \etal{} implemented a supervisor allowing the robot to estimate the human's mental state about the environment and the states of the goals, plans and actions, while executing shared plans~\cite{devin_2016_implemented}.


\section{Challenges}\todo{needed ? don't know what to put inside...}




\ifdefined\included
\else
\bibliographystyle{acm}
\bibliography{These}
\end{document}
\fi

